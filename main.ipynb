{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7acba0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import torch\n",
    "from gliner import GLiNER\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import re\n",
    "from pprint import pprint\n",
    "import random\n",
    "from utilities import *\n",
    "from chunking import EnhancedSemanticChunker\n",
    "from langchain_qdrant import Qdrant\n",
    "from initialize_groq import init_groq\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1831e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/emails.csv\")\n",
    "idx = 1000\n",
    "msg = df['message'][idx]\n",
    "VECTOR_DB_NAME = \"emails_e5_qdrant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdc5ec",
   "metadata": {},
   "source": [
    "THIS IS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd3f509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <1081797.1075855696183.JavaMail.evans@thyme>\n",
      "Date: Thu, 15 Mar 2001 07:39:00 -0800 (PST)\n",
      "From: phillip.allen@enron.com\n",
      "To: stagecoachmama@hotmail.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: stagecoachmama@hotmail.com\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_June2001\\Notes Folders\\All documents\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Lucy,\n",
      "\n",
      "Here is the rentroll.\n",
      "\n",
      "My only questions are about #18, #25, and #37 missed rent.  Any special \n",
      "reasons?\n",
      "\n",
      "It looks like there are five vacancies #2,12,20a,35,40.  If you want to run \n",
      "an ad in the paper with a $50 discount that is fine.\n",
      "I will write you a letter of recommendation.  When do you need it?  You can \n",
      "use me as a reference.  In the next two weeks we should really have a good \n",
      "idea whether the sale is going through.\n",
      "\n",
      "Phillip\n",
      "essage: 1081797.1075855696183.avaail.evans@thymeate: hu, 15 ar 2001 07:39:00 0800 ()rom: phillip.allen@enron.como: stagecoachmama@hotmail.comubject: imeersion: 1.0ontentype: text/plain; charsetusasciiontentransferncoding: 7bitrom: hillip lleno: stagecoachmama@hotmail.comcc: bcc: older: hillip_llen_une2001otes oldersll documentsrigin: llenileame: pallen.nsfucy,ere is the rentroll.y only questions are about 18, 25, and 37 missed rent. ny special reasons?t looks like there are five vacancies 2,12,20a,35,40. f you want to run an ad in the paper with a 50 discount that is fine. will write you a letter of recommendation. hen do you need it? ou can use me as a reference. n the next two weeks we should really have a good idea whether the sale is going through.hillip\n",
      "cuda available? False\n"
     ]
    }
   ],
   "source": [
    "print(msg)\n",
    "print(clean_text(msg))\n",
    "print('cuda available?',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81e1e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Microsoft E5 model\n",
    "model_kwargs = {'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}  # does l2 norm for the cos sim\n",
    "modelemb = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/e5-base-v2\", \n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fc70b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 57456.22it/s]\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initializing GLiNER model\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gliner_model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n",
    "gliner_model.config.max_len = 512\n",
    "gliner_model.to(DEVICE)\n",
    "\n",
    "# model entity labels configuration\n",
    "labels = [\"date\", \"location\", \"person\", \"action\", \"finance\", \"legal\", \"event\", \"product\", \"organization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43a668ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing EnhancedSemanticChunker\n",
    "enhanced_chunker = EnhancedSemanticChunker(\n",
    "    embeddings=modelemb,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=50,  \n",
    "    min_chunk_size=5,\n",
    "    overlap_sentences=2,  \n",
    "    gliner_model=gliner_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d458fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "metadata, split_msg = extract_email_metadata(msg, idx)\n",
    "msg_start = split_msg.index(\"X-FileName:\")\n",
    "full_content = clean_text(\" \".join(split_msg[msg_start + 2:]))\n",
    "# print(full_content)\n",
    "# Create document with the enhanced chunker\n",
    "documents = enhanced_chunker.create_documents(\n",
    "    texts=[full_content],\n",
    "    metadatas=[metadata]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a358f",
   "metadata": {},
   "source": [
    "THIS IS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24654ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks after deduplication: 5\n",
      "\n",
      "--- Unique Chunk 1/5 ---\n",
      "Content: passage: ucy, ere is the rentroll. y only questions are about 18, 25, and 37 missed rent. ny special reasons? t looks like there are five vacancies 2,12,20a,35,40. f you want to run an ad in the paper with a 50 discount that is fine.\n",
      "Metadata: {'Message-ID': '<1081797.1075855696183.JavaMail.evans@thyme>', 'filename': 'allen-p/all_documents/462.', 'sender': 'phillip.allen@enron.com', 'recipient': 'stagecoachmama@hotmail.com', 'date': '03-15-2001', 'subject': '', 'entities': 'This passage contains locations mentioned include ny. '}\n",
      "\n",
      "--- Unique Chunk 2/5 ---\n",
      "Content: passage: y only questions are about 18, 25, and 37 missed rent. ny special reasons? t looks like there are five vacancies 2,12,20a,35,40. f you want to run an ad in the paper with a 50 discount that is fine. will write you a letter of recommendation. hen do you need it?\n",
      "Metadata: {'Message-ID': '<1081797.1075855696183.JavaMail.evans@thyme>', 'filename': 'allen-p/all_documents/462.', 'sender': 'phillip.allen@enron.com', 'recipient': 'stagecoachmama@hotmail.com', 'date': '03-15-2001', 'subject': '', 'entities': 'This passage contains locations mentioned include ny; people mentioned include you; legal terms mentioned include letter of recommendation. '}\n",
      "\n",
      "--- Unique Chunk 3/5 ---\n",
      "Content: passage: t looks like there are five vacancies 2,12,20a,35,40. f you want to run an ad in the paper with a 50 discount that is fine. will write you a letter of recommendation. hen do you need it? ou can use me as a reference.\n",
      "Metadata: {'Message-ID': '<1081797.1075855696183.JavaMail.evans@thyme>', 'filename': 'allen-p/all_documents/462.', 'sender': 'phillip.allen@enron.com', 'recipient': 'stagecoachmama@hotmail.com', 'date': '03-15-2001', 'subject': '', 'entities': 'This passage contains people mentioned include you, ou; locations mentioned include paper; legal terms mentioned include letter of recommendation. '}\n",
      "\n",
      "--- Unique Chunk 4/5 ---\n",
      "Content: passage: f you want to run an ad in the paper with a 50 discount that is fine. will write you a letter of recommendation. hen do you need it? ou can use me as a reference. n the next two weeks we should really have a good idea whether the sale is going through.\n",
      "Metadata: {'Message-ID': '<1081797.1075855696183.JavaMail.evans@thyme>', 'filename': 'allen-p/all_documents/462.', 'sender': 'phillip.allen@enron.com', 'recipient': 'stagecoachmama@hotmail.com', 'date': '03-15-2001', 'subject': '', 'entities': 'This passage contains people mentioned include you, ou, we; locations mentioned include paper; events mentioned include 50 discount, sale; legal terms mentioned include letter of recommendation; dates mentioned include next two weeks. '}\n",
      "\n",
      "--- Unique Chunk 5/5 ---\n",
      "Content: passage: will write you a letter of recommendation. hen do you need it? ou can use me as a reference. n the next two weeks we should really have a good idea whether the sale is going through. hillip\n",
      "Metadata: {'Message-ID': '<1081797.1075855696183.JavaMail.evans@thyme>', 'filename': 'allen-p/all_documents/462.', 'sender': 'phillip.allen@enron.com', 'recipient': 'stagecoachmama@hotmail.com', 'date': '03-15-2001', 'subject': '', 'entities': 'This passage contains people mentioned include you, ou, hillip; dates mentioned include n the next two weeks; events mentioned include sale. '}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks after deduplication: {len(documents)}\")\n",
    "\n",
    "# Now use 'deduplicated_documents' for further processing (indexing, etc.)\n",
    "for i, doc in enumerate(documents):  \n",
    "    print(f\"\\n--- Unique Chunk {i+1}/{len(documents)} ---\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d812c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Qdrant.from_existing_collection(modelemb, \"emails_e5_qdrant\", VECTOR_DB_NAME)\n",
    "model = modelemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "            You are an expert in vector-based retrieval for Qdrant databases. The database stores semantically chunked email passages, each consisting of one sentence plus one sentence before and after for context. Each passage is enriched with metadata, including fields such as: date, location, person, action, finance, legal, event, product, and organization.\n",
    "            Your task is to reformulate the following user question into a precise, high-quality natural language query optimized for semantic similarity search. Leverage the structure of the vector schema and, when appropriate, integrate terminology related to the metadata fields to improve retrieval relevance.\n",
    "            Context: \"{context}\"\n",
    "            Original user question: \"{input}\"\n",
    "            Return ONLY the reformulated query, suitable for vector search. Do NOT include any explanations or additional text.\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "document_prompt = PromptTemplate.from_template(\n",
    "    \"METADATA: Source: {sender}\\nDate: {date}\\n Recipients: {recipient}\\nSubject: {subject}\\nEntities: {entities}\\n\\nContent: {page_content}\"\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={'k':20, 'search_type':'mmr','lambda_mult':0.2})\n",
    "\n",
    "_, llm, groqllm = init_groq(model_name=\"llama-3.3-70b-versatile\")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt=prompt, document_prompt=document_prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Retrieve Top-K Similar Documents (Initial Broad Search)\n",
    "# retriever_topk = db.as_retriever(search_kwargs={'k': 20,'fetch_k' : 100, 'search_type': 'similarity_s core_threshold','score_threshold':0.75})  # Retrieve more docs first\n",
    "retriever_topk = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold':0.65,'k':10})\n",
    "# MMR for Diversity (Reduce Redundant Docs)\n",
    "retriever_mmr = db.as_retriever(search_type=\"mmr\", search_kwargs={'k':10,'lambda_mult': 1})  \n",
    "\n",
    "# Create the Hybrid Retrieval Pipeline\n",
    "retrieval_chain_topk = create_retrieval_chain(retriever_topk, document_chain)  # Initial broad search\n",
    "retrieval_chain_mmr = create_retrieval_chain(retriever_mmr, document_chain)    # Apply MMR re-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc5dd0",
   "metadata": {},
   "source": [
    "THIS IS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6d4c2d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Collection emails_e5_qdrant not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mquery: is MSEB an indian company? 402 crore amount? its relation to enron?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# pprint.pprint(retrieval_chain_topk.invoke({\"input\":query}))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pprint.pprint(\u001b[43mretrieval_chain_mmr\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m test_questions = [\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat does randy need to send a schedule of?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat are some of randy\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms action items?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat did jeffrey skilling tell john arnold\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m ]\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m test_questions:\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Define query\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:5358\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5355\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5356\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5357\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5359\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:496\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    491\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    492\u001b[39m     \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    493\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    494\u001b[39m     **kwargs: Any,\n\u001b[32m    495\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:483\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    482\u001b[39m     **\u001b[38;5;28minput\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    488\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:3728\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3723\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3724\u001b[39m         futures = [\n\u001b[32m   3725\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3726\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3727\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3728\u001b[39m         output = \u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   3729\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3730\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:3728\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   3723\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3724\u001b[39m         futures = [\n\u001b[32m   3725\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3726\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3727\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3728\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3729\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3730\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:3712\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input, config, key)\u001b[39m\n\u001b[32m   3706\u001b[39m child_config = patch_config(\n\u001b[32m   3707\u001b[39m     config,\n\u001b[32m   3708\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3709\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3710\u001b[39m )\n\u001b[32m   3711\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3713\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3714\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3716\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:5358\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5355\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5356\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5357\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5359\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/retrievers.py:259\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:1083\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1081\u001b[39m     docs = [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33mmmr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_marginal_relevance_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1085\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msearch_type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.search_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not allowed.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_qdrant/vectorstores.py:768\u001b[39m, in \u001b[36mQdrant.max_marginal_relevance_search\u001b[39m\u001b[34m(self, query, k, fetch_k, lambda_mult, filter, search_params, score_threshold, consistency, **kwargs)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[32m    730\u001b[39m \n\u001b[32m    731\u001b[39m \u001b[33;03mMaximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    765\u001b[39m \u001b[33;03m    List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[32m    766\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    767\u001b[39m query_embedding = \u001b[38;5;28mself\u001b[39m._embed_query(query)\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_marginal_relevance_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_mult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_qdrant/vectorstores.py:894\u001b[39m, in \u001b[36mQdrant.max_marginal_relevance_search_by_vector\u001b[39m\u001b[34m(self, embedding, k, fetch_k, lambda_mult, filter, search_params, score_threshold, consistency, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmax_marginal_relevance_search_by_vector\u001b[39m(\n\u001b[32m    846\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    847\u001b[39m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    855\u001b[39m     **kwargs: Any,\n\u001b[32m    856\u001b[39m ) -> List[Document]:\n\u001b[32m    857\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[32m    858\u001b[39m \n\u001b[32m    859\u001b[39m \u001b[33;03m    Maximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    892\u001b[39m \u001b[33;03m        List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_marginal_relevance_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlambda_mult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[32m0\u001b[39m), results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/langchain_qdrant/vectorstores.py:1024\u001b[39m, in \u001b[36mQdrant.max_marginal_relevance_search_with_score_by_vector\u001b[39m\u001b[34m(self, embedding, k, fetch_k, lambda_mult, filter, search_params, score_threshold, consistency, **kwargs)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vector_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1022\u001b[39m     query_vector = (\u001b[38;5;28mself\u001b[39m.vector_name, query_vector)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_vectors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m embeddings = [\n\u001b[32m   1037\u001b[39m     result.vector.get(\u001b[38;5;28mself\u001b[39m.vector_name)  \u001b[38;5;66;03m# type: ignore[index, union-attr]\u001b[39;00m\n\u001b[32m   1038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vector_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m result.vector\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m   1041\u001b[39m ]\n\u001b[32m   1042\u001b[39m mmr_selected = maximal_marginal_relevance(\n\u001b[32m   1043\u001b[39m     np.array(embedding), embeddings, k=k, lambda_mult=lambda_mult\n\u001b[32m   1044\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/qdrant_client/qdrant_client.py:373\u001b[39m, in \u001b[36mQdrantClient.search\u001b[39m\u001b[34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, append_payload, consistency, shard_key_selector, timeout, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m warnings.warn(\n\u001b[32m    368\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m`search` method is deprecated and will be removed in the future.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m Use `query_points` instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    370\u001b[39m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    371\u001b[39m     stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    372\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_vectors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mappend_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mappend_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/qdrant_client/local/qdrant_local.py:215\u001b[39m, in \u001b[36mQdrantLocal.search\u001b[39m\u001b[34m(self, collection_name, query_vector, query_filter, search_params, limit, offset, with_payload, with_vectors, score_threshold, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch\u001b[39m(\n\u001b[32m    197\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    198\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m     **kwargs: Any,\n\u001b[32m    214\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[types.ScoredPoint]:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m collection.search(\n\u001b[32m    217\u001b[39m         query_vector=query_vector,\n\u001b[32m    218\u001b[39m         query_filter=query_filter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m         score_threshold=score_threshold,\n\u001b[32m    224\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gditml/lib/python3.11/site-packages/qdrant_client/local/qdrant_local.py:173\u001b[39m, in \u001b[36mQdrantLocal._get_collection\u001b[39m\u001b[34m(self, collection_name)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collection_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aliases:\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collections[\u001b[38;5;28mself\u001b[39m.aliases[collection_name]]\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Collection emails_e5_qdrant not found"
     ]
    }
   ],
   "source": [
    "query = \"query: is MSEB an indian company? 402 crore amount? its relation to enron?\"\n",
    "# pprint.pprint(retrieval_chain_topk.invoke({\"input\":query}))\n",
    "pprint.pprint(retrieval_chain_mmr.invoke({\"input\":query}))\n",
    "\n",
    "test_questions = [\n",
    "    \"What does randy need to send a schedule of?\",\n",
    "    \"What are some of randy's action items?\",\n",
    "    \"What is Philip's proposal focused on, and can you provided details about the proposal?\",\n",
    "    \"Can you provide me more detail about the microturbine power generation deal?\",\n",
    "    \"What needs to be faxed?\",\n",
    "    \"Are there hints of a scandal in the emails?\",\n",
    "    \"What did jeffrey skilling tell john arnold\"\n",
    "]\n",
    "for text in test_questions:\n",
    "    # Define query\n",
    "    query = \"query: \" + text\n",
    "    pprint.pprint(retrieval_chain_mmr.invoke({\"input\":query}))\n",
    "\n",
    "test_questions = [\n",
    "    \"query: What does randy need to send a schedule of?\",\n",
    "    \"query: What are some of randy's action items?\",\n",
    "    \"query: What is Philip's proposal focused on, and can you provided details about the proposal?\",\n",
    "    \"query: Can you provide me more detail about the microturbine power generation deal?\",\n",
    "    \"query: What needs to be faxed?\"\n",
    "]\n",
    "for text in test_questions:\n",
    "    print(\"=========================================================\")\n",
    "    query = \"query: \" + text\n",
    "    query_embedding = np.array(model.embed_query(query))\n",
    "    # query_embedding = l2_normalize(query_embedding)  \n",
    "    topk_results = db.similarity_search_with_score_by_vector(\n",
    "        embedding=query_embedding.tolist(),  # List[float]\n",
    "        k=5\n",
    "    )\n",
    "\n",
    "    mmr_results = db.max_marginal_relevance_search_with_score_by_vector(\n",
    "        embedding=query_embedding.tolist(),  # List[float]\n",
    "        k=5,\n",
    "        lambda_mult=0.8         \n",
    "    )\n",
    "\n",
    "    # Sort by L2 distance (ascending: lower = more similar)\n",
    "    topk_sorted = sorted(topk_results, key=lambda x: x[1])\n",
    "    \n",
    "    mmr_sorted = sorted(mmr_results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display results with L2 distance and cosine similarity\n",
    "    for doc, mmr_score in mmr_sorted:\n",
    "        # docembedding = l2_normalize(np.array(modelemb.embed_documents([doc.page_content])))\n",
    "        # cos_sim = float(np.dot(query_embedding, docembedding.reshape(-1)))\n",
    "        pprint.pprint(f\"Document:\\n {doc.page_content} | MMR Score: {mmr_score:.4f}\")\n",
    "        \n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    for doc, l2_score in topk_sorted:\n",
    "        # Convert L2 distance to cosine similarity (assuming L2-normalized)\n",
    "        cosine_sim = 1 - (l2_score ** 2) / 2\n",
    "        pprint.pprint(f\"Document: {doc.page_content[:100]} | L2 Distance: {l2_score:.4f} | Cosine Sim: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e602bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    state[\"messages\"]\n",
    "    messages = state[\"messages\"]\n",
    "    #print(messages)\n",
    "    groqllm.groq_api_key = random.choice(api_keys)\n",
    "    llm_with_tool = groqllm.bind_tools([ragtool])\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "    \n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "@tool\n",
    "def ragtool(query: str, num_docs: int) -> str:\n",
    "    \"\"\"\n",
    "    This is a retrieval-augmented generation (RAG) tool that queries a vector store \n",
    "    containing Enron emails.\n",
    "    \n",
    "    Parameters:\n",
    "    query (str): The input query for retrieval.\n",
    "    num_docs (int): The number of documents to retrieve.\n",
    "    Returns:\n",
    "    str: The retrieved answer from the vector store.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer = retrieval_chain_topk.invoke({\"input\": query})['answer']\n",
    "        return f\"Here is the ANSWER. \\n ```{answer}```\\n DO NOT USE THE TOOL REPEATEDLY. SHOW THE ANSWER TO THE USER. \\n\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Failed to retrieve answer. Details: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolnode = ToolNode([ragtool])\n",
    "\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(MessagesState)    \n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(toolnode)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    router_function,\n",
    "    {\n",
    "       \"tools\": \"tools\",\n",
    "       END: END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0d77d",
   "metadata": {},
   "source": [
    "THIS IS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ec88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_png\n",
    "display_png(app.get_graph().draw_mermaid_png(),raw=True)\n",
    "\n",
    "import time\n",
    "while True:\n",
    "    theinput = input(\"Enter something: \")\n",
    "    if 'exit' in theinput:\n",
    "        break\n",
    "    inp = {\"messages\":[theinput]}\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": 1}}\n",
    "    events = app.stream(inp, config=config, stream_mode=\"values\")\n",
    "\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multi-query prompt template\n",
    "# This template instructs the LLM to generate multiple search queries from a single user question\n",
    "multi_template = \"\"\"You are an expert at querying search engines. You specialize in understanding natural language queries and generating multiple search\n",
    "queries that, taken together, would help provide a comprehensive answer to the user's question.\n",
    "\n",
    "Main Question: {question}\n",
    "\n",
    "Let's break this down. Generate 4 search queries for querying a knowledge store about emails. \n",
    "Make sure these queries use language that would appear in actual emails.\n",
    "Remember to keep them short, using keywords that would be found in emails.\n",
    "Keep them straightforward and distinct from each other.\n",
    "Formulate them from different angles to solve the main query.\n",
    "\n",
    "Return a bullet list with • at the start of each question:\n",
    "\n",
    "• query 1\n",
    "• query 2\n",
    "• etc.\n",
    "\"\"\"\n",
    "\n",
    "# Create a processor to generate multiple search queries from a single question\n",
    "multi_query_prompt = PromptTemplate.from_template(multi_template)\n",
    "multi_query_chain = multi_query_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_query(main_query, query_generator=multi_query_chain, single_query_chain=retrieval_chain_topk):\n",
    "    \"\"\"\n",
    "    Run a multi-query retrieval process to improve search results accuracy.\n",
    "    \n",
    "    This function:\n",
    "    1. Takes a user query and generates multiple search queries using the LLM\n",
    "    2. Executes each generated query against the retrieval system\n",
    "    3. Combines and summarizes the results for a comprehensive answer\n",
    "    \n",
    "    Args:\n",
    "        main_query: The original user question\n",
    "        query_generator: Chain to generate multiple search queries\n",
    "        single_query_chain: Chain to execute individual queries\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with consolidated results and performance metrics\n",
    "    \"\"\"\n",
    "    # Start timing the process\n",
    "    start_time = total_start_time = time.time()\n",
    "    \n",
    "    # Generate multiple search queries from the main question\n",
    "    result = query_generator.invoke({\"question\": main_query})\n",
    "    \n",
    "    # Extract the generated queries from the bullet point list\n",
    "    sub_questions = [q.strip() for q in result.split('•') if q.strip()]\n",
    "    \n",
    "    # Record query generation time\n",
    "    gen_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Track all retrieved documents and their sources\n",
    "    all_docs = []\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each generated query\n",
    "    print(\"Generated Questions:\")\n",
    "    for i, question in enumerate(sub_questions):\n",
    "        print(f\"{i+1}. {question}\")\n",
    "        # Execute the query against the retrieval system\n",
    "        chain_result = single_query_chain.invoke({\"input\": question})\n",
    "        all_results.append(chain_result)\n",
    "        \n",
    "        # Track the documents retrieved for this query\n",
    "        if \"context\" in chain_result:\n",
    "            all_docs.extend(chain_result[\"context\"])\n",
    "    \n",
    "    # Record search execution time\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate combined result using the original query\n",
    "    # This ensures the answer is based on all retrieved information\n",
    "    final_answer = single_query_chain.invoke({\n",
    "        \"input\": main_query,\n",
    "        \"context\": all_docs[:10]  # Limit to top 10 most relevant documents\n",
    "    })\n",
    "    \n",
    "    # Record total processing time\n",
    "    total_time = time.time() - total_start_time\n",
    "    \n",
    "    # Return comprehensive results with timing metrics\n",
    "    return {\n",
    "        \"main_query\": main_query,\n",
    "        \"generated_queries\": sub_questions,\n",
    "        \"individual_answers\": all_results,\n",
    "        \"final_answer\": final_answer[\"answer\"],\n",
    "        \"all_docs\": all_docs,\n",
    "        \"timing\": {\n",
    "            \"query_generation\": gen_time,\n",
    "            \"search_execution\": search_time,\n",
    "            \"total_processing\": total_time\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfaf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries for evaluating retrieval performance\n",
    "test_queries = [\n",
    "    \"What do we know about Skilling's involvement in Enron's financial reporting?\",\n",
    "    \"What are the main topics discussed in emails from Kenneth Lay?\",\n",
    "    \"How did Enron executives discuss the California energy crisis in their emails?\",\n",
    "    \"What discussions were happening about LJM partnerships in the months before Enron's collapse?\",\n",
    "    \"What was discussed about mark-to-market accounting in emails?\",\n",
    "    \"Who was responsible for overseeing Special Purpose Entities at Enron?\",\n",
    "    \"What communication happened regarding Raptor structures?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage - process a test query with advanced retrieval\n",
    "for i in range(len(test_queries)):\n",
    "    result = run_multi_query(test_queries[i])\n",
    "    # Print the final answer\n",
    "    print(result[\"final_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gditml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
